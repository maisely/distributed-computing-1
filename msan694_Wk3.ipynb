{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definition: Key-value pairs, commonly for operations such as aggregations and ETL\n",
    "    + e.g. student ID as key and their information as values\n",
    "    + Key: int, str, tuples, etc. \n",
    "    + Values: lists, tuples, dicts, set, etc. - can be simple obj to data structures\n",
    "- Key could be duplicate, same key can appear in each element\n",
    "- Allow operations on each key in parallel . regroup data cross the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"./data/README.md\")\n",
    "words = lines.flatMap(lambda l: l.split(\" \")).map(lambda x: (x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'#', 1),\n",
       "  (u'Apache', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'is', 1),\n",
       "  (u'a', 1),\n",
       "  (u'fast', 1),\n",
       "  (u'and', 1),\n",
       "  (u'general', 1),\n",
       "  (u'cluster', 1),\n",
       "  (u'computing', 1),\n",
       "  (u'system', 1),\n",
       "  (u'for', 1),\n",
       "  (u'Big', 1),\n",
       "  (u'Data.', 1),\n",
       "  (u'It', 1),\n",
       "  (u'provides', 1),\n",
       "  (u'high-level', 1),\n",
       "  (u'APIs', 1),\n",
       "  (u'in', 1),\n",
       "  (u'Scala,', 1),\n",
       "  (u'Java,', 1),\n",
       "  (u'Python,', 1),\n",
       "  (u'and', 1),\n",
       "  (u'R,', 1),\n",
       "  (u'and', 1),\n",
       "  (u'an', 1),\n",
       "  (u'optimized', 1),\n",
       "  (u'engine', 1),\n",
       "  (u'that', 1),\n",
       "  (u'supports', 1),\n",
       "  (u'general', 1),\n",
       "  (u'computation', 1),\n",
       "  (u'graphs', 1),\n",
       "  (u'for', 1),\n",
       "  (u'data', 1),\n",
       "  (u'analysis.', 1),\n",
       "  (u'It', 1),\n",
       "  (u'also', 1),\n",
       "  (u'supports', 1),\n",
       "  (u'a', 1),\n",
       "  (u'rich', 1),\n",
       "  (u'set', 1),\n",
       "  (u'of', 1),\n",
       "  (u'higher-level', 1),\n",
       "  (u'tools', 1),\n",
       "  (u'including', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'SQL', 1),\n",
       "  (u'for', 1),\n",
       "  (u'SQL', 1),\n",
       "  (u'and', 1),\n",
       "  (u'DataFrames,', 1),\n",
       "  (u'MLlib', 1),\n",
       "  (u'for', 1),\n",
       "  (u'machine', 1),\n",
       "  (u'learning,', 1),\n",
       "  (u'GraphX', 1),\n",
       "  (u'for', 1),\n",
       "  (u'graph', 1),\n",
       "  (u'processing,', 1),\n",
       "  (u'and', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'Streaming', 1),\n",
       "  (u'for', 1),\n",
       "  (u'stream', 1),\n",
       "  (u'processing.', 1),\n",
       "  (u'', 1),\n",
       "  (u'<http://spark.apache.org/>', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'##', 1),\n",
       "  (u'Online', 1),\n",
       "  (u'Documentation', 1),\n",
       "  (u'', 1),\n",
       "  (u'You', 1),\n",
       "  (u'can', 1),\n",
       "  (u'find', 1),\n",
       "  (u'the', 1),\n",
       "  (u'latest', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'documentation,', 1),\n",
       "  (u'including', 1),\n",
       "  (u'a', 1),\n",
       "  (u'programming', 1),\n",
       "  (u'guide,', 1),\n",
       "  (u'on', 1),\n",
       "  (u'the', 1),\n",
       "  (u'[project', 1),\n",
       "  (u'web', 1),\n",
       "  (u'page](http://spark.apache.org/documentation.html)', 1),\n",
       "  (u'and', 1),\n",
       "  (u'[project', 1),\n",
       "  (u'wiki](https://cwiki.apache.org/confluence/display/SPARK).', 1),\n",
       "  (u'This', 1),\n",
       "  (u'README', 1),\n",
       "  (u'file', 1),\n",
       "  (u'only', 1),\n",
       "  (u'contains', 1),\n",
       "  (u'basic', 1),\n",
       "  (u'setup', 1),\n",
       "  (u'instructions.', 1),\n",
       "  (u'', 1),\n",
       "  (u'##', 1),\n",
       "  (u'Building', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'is', 1),\n",
       "  (u'built', 1),\n",
       "  (u'using', 1),\n",
       "  (u'[Apache', 1),\n",
       "  (u'Maven](http://maven.apache.org/).', 1),\n",
       "  (u'To', 1),\n",
       "  (u'build', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'and', 1),\n",
       "  (u'its', 1),\n",
       "  (u'example', 1),\n",
       "  (u'programs,', 1),\n",
       "  (u'run:', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'build/mvn', 1),\n",
       "  (u'-DskipTests', 1),\n",
       "  (u'clean', 1),\n",
       "  (u'package', 1),\n",
       "  (u'', 1),\n",
       "  (u'(You', 1),\n",
       "  (u'do', 1),\n",
       "  (u'not', 1),\n",
       "  (u'need', 1),\n",
       "  (u'to', 1),\n",
       "  (u'do', 1),\n",
       "  (u'this', 1),\n",
       "  (u'if', 1),\n",
       "  (u'you', 1),\n",
       "  (u'downloaded', 1),\n",
       "  (u'a', 1),\n",
       "  (u'pre-built', 1),\n",
       "  (u'package.)', 1),\n",
       "  (u'', 1),\n",
       "  (u'You', 1),\n",
       "  (u'can', 1),\n",
       "  (u'build', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'using', 1),\n",
       "  (u'more', 1),\n",
       "  (u'than', 1),\n",
       "  (u'one', 1),\n",
       "  (u'thread', 1),\n",
       "  (u'by', 1),\n",
       "  (u'using', 1),\n",
       "  (u'the', 1),\n",
       "  (u'-T', 1),\n",
       "  (u'option', 1),\n",
       "  (u'with', 1),\n",
       "  (u'Maven,', 1),\n",
       "  (u'see', 1),\n",
       "  (u'[\"Parallel', 1),\n",
       "  (u'builds', 1),\n",
       "  (u'in', 1),\n",
       "  (u'Maven', 1),\n",
       "  (u'3\"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).',\n",
       "   1),\n",
       "  (u'More', 1),\n",
       "  (u'detailed', 1),\n",
       "  (u'documentation', 1),\n",
       "  (u'is', 1),\n",
       "  (u'available', 1),\n",
       "  (u'from', 1),\n",
       "  (u'the', 1),\n",
       "  (u'project', 1),\n",
       "  (u'site,', 1),\n",
       "  (u'at', 1),\n",
       "  (u'[\"Building', 1),\n",
       "  (u'Spark\"](http://spark.apache.org/docs/latest/building-spark.html).', 1),\n",
       "  (u'For', 1),\n",
       "  (u'developing', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'using', 1),\n",
       "  (u'an', 1),\n",
       "  (u'IDE,', 1),\n",
       "  (u'see', 1),\n",
       "  (u'[Eclipse](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-Eclipse)',\n",
       "   1),\n",
       "  (u'and', 1),\n",
       "  (u'[IntelliJ](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-IntelliJ).',\n",
       "   1),\n",
       "  (u'', 1),\n",
       "  (u'##', 1),\n",
       "  (u'Interactive', 1),\n",
       "  (u'Scala', 1),\n",
       "  (u'Shell', 1),\n",
       "  (u'', 1),\n",
       "  (u'The', 1),\n",
       "  (u'easiest', 1),\n",
       "  (u'way', 1),\n",
       "  (u'to', 1),\n",
       "  (u'start', 1),\n",
       "  (u'using', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'is', 1),\n",
       "  (u'through', 1),\n",
       "  (u'the', 1),\n",
       "  (u'Scala', 1),\n",
       "  (u'shell:', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'./bin/spark-shell', 1),\n",
       "  (u'', 1),\n",
       "  (u'Try', 1),\n",
       "  (u'the', 1),\n",
       "  (u'following', 1),\n",
       "  (u'command,', 1),\n",
       "  (u'which', 1),\n",
       "  (u'should', 1),\n",
       "  (u'return', 1),\n",
       "  (u'1000:', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'scala>', 1),\n",
       "  (u'sc.parallelize(1', 1),\n",
       "  (u'to', 1),\n",
       "  (u'1000).count()', 1),\n",
       "  (u'', 1),\n",
       "  (u'##', 1),\n",
       "  (u'Interactive', 1),\n",
       "  (u'Python', 1),\n",
       "  (u'Shell', 1),\n",
       "  (u'', 1),\n",
       "  (u'Alternatively,', 1),\n",
       "  (u'if', 1),\n",
       "  (u'you', 1),\n",
       "  (u'prefer', 1),\n",
       "  (u'Python,', 1),\n",
       "  (u'you', 1),\n",
       "  (u'can', 1),\n",
       "  (u'use', 1),\n",
       "  (u'the', 1),\n",
       "  (u'Python', 1),\n",
       "  (u'shell:', 1)],\n",
       " [(u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'./bin/pyspark', 1),\n",
       "  (u'', 1),\n",
       "  (u'And', 1),\n",
       "  (u'run', 1),\n",
       "  (u'the', 1),\n",
       "  (u'following', 1),\n",
       "  (u'command,', 1),\n",
       "  (u'which', 1),\n",
       "  (u'should', 1),\n",
       "  (u'also', 1),\n",
       "  (u'return', 1),\n",
       "  (u'1000:', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'>>>', 1),\n",
       "  (u'sc.parallelize(range(1000)).count()', 1),\n",
       "  (u'', 1),\n",
       "  (u'##', 1),\n",
       "  (u'Example', 1),\n",
       "  (u'Programs', 1),\n",
       "  (u'', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'also', 1),\n",
       "  (u'comes', 1),\n",
       "  (u'with', 1),\n",
       "  (u'several', 1),\n",
       "  (u'sample', 1),\n",
       "  (u'programs', 1),\n",
       "  (u'in', 1),\n",
       "  (u'the', 1),\n",
       "  (u'`examples`', 1),\n",
       "  (u'directory.', 1),\n",
       "  (u'To', 1),\n",
       "  (u'run', 1),\n",
       "  (u'one', 1),\n",
       "  (u'of', 1),\n",
       "  (u'them,', 1),\n",
       "  (u'use', 1),\n",
       "  (u'`./bin/run-example', 1),\n",
       "  (u'<class>', 1),\n",
       "  (u'[params]`.', 1),\n",
       "  (u'For', 1),\n",
       "  (u'example:', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'./bin/run-example', 1),\n",
       "  (u'SparkPi', 1),\n",
       "  (u'', 1),\n",
       "  (u'will', 1),\n",
       "  (u'run', 1),\n",
       "  (u'the', 1),\n",
       "  (u'Pi', 1),\n",
       "  (u'example', 1),\n",
       "  (u'locally.', 1),\n",
       "  (u'', 1),\n",
       "  (u'You', 1),\n",
       "  (u'can', 1),\n",
       "  (u'set', 1),\n",
       "  (u'the', 1),\n",
       "  (u'MASTER', 1),\n",
       "  (u'environment', 1),\n",
       "  (u'variable', 1),\n",
       "  (u'when', 1),\n",
       "  (u'running', 1),\n",
       "  (u'examples', 1),\n",
       "  (u'to', 1),\n",
       "  (u'submit', 1),\n",
       "  (u'examples', 1),\n",
       "  (u'to', 1),\n",
       "  (u'a', 1),\n",
       "  (u'cluster.', 1),\n",
       "  (u'This', 1),\n",
       "  (u'can', 1),\n",
       "  (u'be', 1),\n",
       "  (u'a', 1),\n",
       "  (u'mesos://', 1),\n",
       "  (u'or', 1),\n",
       "  (u'spark://', 1),\n",
       "  (u'URL,', 1),\n",
       "  (u'\"yarn\"', 1),\n",
       "  (u'to', 1),\n",
       "  (u'run', 1),\n",
       "  (u'on', 1),\n",
       "  (u'YARN,', 1),\n",
       "  (u'and', 1),\n",
       "  (u'\"local\"', 1),\n",
       "  (u'to', 1),\n",
       "  (u'run', 1),\n",
       "  (u'locally', 1),\n",
       "  (u'with', 1),\n",
       "  (u'one', 1),\n",
       "  (u'thread,', 1),\n",
       "  (u'or', 1),\n",
       "  (u'\"local[N]\"', 1),\n",
       "  (u'to', 1),\n",
       "  (u'run', 1),\n",
       "  (u'locally', 1),\n",
       "  (u'with', 1),\n",
       "  (u'N', 1),\n",
       "  (u'threads.', 1),\n",
       "  (u'You', 1),\n",
       "  (u'can', 1),\n",
       "  (u'also', 1),\n",
       "  (u'use', 1),\n",
       "  (u'an', 1),\n",
       "  (u'abbreviated', 1),\n",
       "  (u'class', 1),\n",
       "  (u'name', 1),\n",
       "  (u'if', 1),\n",
       "  (u'the', 1),\n",
       "  (u'class', 1),\n",
       "  (u'is', 1),\n",
       "  (u'in', 1),\n",
       "  (u'the', 1),\n",
       "  (u'`examples`', 1),\n",
       "  (u'package.', 1),\n",
       "  (u'For', 1),\n",
       "  (u'instance:', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'MASTER=spark://host:7077', 1),\n",
       "  (u'./bin/run-example', 1),\n",
       "  (u'SparkPi', 1),\n",
       "  (u'', 1),\n",
       "  (u'Many', 1),\n",
       "  (u'of', 1),\n",
       "  (u'the', 1),\n",
       "  (u'example', 1),\n",
       "  (u'programs', 1),\n",
       "  (u'print', 1),\n",
       "  (u'usage', 1),\n",
       "  (u'help', 1),\n",
       "  (u'if', 1),\n",
       "  (u'no', 1),\n",
       "  (u'params', 1),\n",
       "  (u'are', 1),\n",
       "  (u'given.', 1),\n",
       "  (u'', 1),\n",
       "  (u'##', 1),\n",
       "  (u'Running', 1),\n",
       "  (u'Tests', 1),\n",
       "  (u'', 1),\n",
       "  (u'Testing', 1),\n",
       "  (u'first', 1),\n",
       "  (u'requires', 1),\n",
       "  (u'[building', 1),\n",
       "  (u'Spark](#building-spark).', 1),\n",
       "  (u'Once', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'is', 1),\n",
       "  (u'built,', 1),\n",
       "  (u'tests', 1),\n",
       "  (u'can', 1),\n",
       "  (u'be', 1),\n",
       "  (u'run', 1),\n",
       "  (u'using:', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'', 1),\n",
       "  (u'./dev/run-tests', 1),\n",
       "  (u'', 1),\n",
       "  (u'Please', 1),\n",
       "  (u'see', 1),\n",
       "  (u'the', 1),\n",
       "  (u'guidance', 1),\n",
       "  (u'on', 1),\n",
       "  (u'how', 1),\n",
       "  (u'to', 1),\n",
       "  (u'[run', 1),\n",
       "  (u'tests', 1),\n",
       "  (u'for', 1),\n",
       "  (u'a', 1),\n",
       "  (u'module,', 1),\n",
       "  (u'or', 1),\n",
       "  (u'individual', 1),\n",
       "  (u'tests](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools).',\n",
       "   1),\n",
       "  (u'', 1),\n",
       "  (u'##', 1),\n",
       "  (u'A', 1),\n",
       "  (u'Note', 1),\n",
       "  (u'About', 1),\n",
       "  (u'Hadoop', 1),\n",
       "  (u'Versions', 1),\n",
       "  (u'', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'uses', 1),\n",
       "  (u'the', 1),\n",
       "  (u'Hadoop', 1),\n",
       "  (u'core', 1),\n",
       "  (u'library', 1),\n",
       "  (u'to', 1),\n",
       "  (u'talk', 1),\n",
       "  (u'to', 1),\n",
       "  (u'HDFS', 1),\n",
       "  (u'and', 1),\n",
       "  (u'other', 1),\n",
       "  (u'Hadoop-supported', 1),\n",
       "  (u'storage', 1),\n",
       "  (u'systems.', 1),\n",
       "  (u'Because', 1),\n",
       "  (u'the', 1),\n",
       "  (u'protocols', 1),\n",
       "  (u'have', 1),\n",
       "  (u'changed', 1),\n",
       "  (u'in', 1),\n",
       "  (u'different', 1),\n",
       "  (u'versions', 1),\n",
       "  (u'of', 1),\n",
       "  (u'Hadoop,', 1),\n",
       "  (u'you', 1),\n",
       "  (u'must', 1),\n",
       "  (u'build', 1),\n",
       "  (u'Spark', 1),\n",
       "  (u'against', 1),\n",
       "  (u'the', 1),\n",
       "  (u'same', 1),\n",
       "  (u'version', 1),\n",
       "  (u'that', 1),\n",
       "  (u'your', 1),\n",
       "  (u'cluster', 1),\n",
       "  (u'runs.', 1),\n",
       "  (u'', 1),\n",
       "  (u'Please', 1),\n",
       "  (u'refer', 1),\n",
       "  (u'to', 1),\n",
       "  (u'the', 1),\n",
       "  (u'build', 1),\n",
       "  (u'documentation', 1),\n",
       "  (u'at', 1),\n",
       "  (u'[\"Specifying', 1),\n",
       "  (u'the', 1),\n",
       "  (u'Hadoop', 1),\n",
       "  (u'Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)',\n",
       "   1),\n",
       "  (u'for', 1),\n",
       "  (u'detailed', 1),\n",
       "  (u'guidance', 1),\n",
       "  (u'on', 1),\n",
       "  (u'building', 1),\n",
       "  (u'for', 1),\n",
       "  (u'a', 1),\n",
       "  (u'particular', 1),\n",
       "  (u'distribution', 1),\n",
       "  (u'of', 1),\n",
       "  (u'Hadoop,', 1),\n",
       "  (u'including', 1),\n",
       "  (u'building', 1),\n",
       "  (u'for', 1),\n",
       "  (u'particular', 1),\n",
       "  (u'Hive', 1),\n",
       "  (u'and', 1),\n",
       "  (u'Hive', 1),\n",
       "  (u'Thriftserver', 1),\n",
       "  (u'distributions.', 1),\n",
       "  (u'', 1),\n",
       "  (u'##', 1),\n",
       "  (u'Configuration', 1),\n",
       "  (u'', 1),\n",
       "  (u'Please', 1),\n",
       "  (u'refer', 1),\n",
       "  (u'to', 1),\n",
       "  (u'the', 1),\n",
       "  (u'[Configuration', 1),\n",
       "  (u'Guide](http://spark.apache.org/docs/latest/configuration.html)', 1),\n",
       "  (u'in', 1),\n",
       "  (u'the', 1),\n",
       "  (u'online', 1),\n",
       "  (u'documentation', 1),\n",
       "  (u'for', 1),\n",
       "  (u'an', 1),\n",
       "  (u'overview', 1),\n",
       "  (u'on', 1),\n",
       "  (u'how', 1),\n",
       "  (u'to', 1),\n",
       "  (u'configure', 1),\n",
       "  (u'Spark.', 1)]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.glom().collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair RDDs Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`keys()`**: return an RDD of keys only (allow duplicates)\n",
    "- **`values()`**: return an RDD of values only (allow duplications)\n",
    "\n",
    "\n",
    "- **`sortByKey()`**: return an RDD sorted by the key - option to set ascending=True/False\n",
    "- **`groupByKey()`**: group value of the same key: `rdd.groupByKey().map(lambda x: (x[0], list(x[1]))` to visualize\n",
    "\n",
    "\n",
    "- **`mapValues()`**: pass each value in the key-value pair RDD through a map fucntion without changing the keys. Retain the original partioning\n",
    "- **`flatMapValues()`**: pass each value in the key-value pair RDD through a flatMap function without changing the keys. Retain the original RDD's partitioning. \n",
    "\n",
    "\n",
    "- **`reduceByKey()`**: Run several parallel reduce operations, one for each key in the data set. When called on a dataset of (Key, Val) pairs. Returns a dataset of (Key, Val) pairs where the values for each key are aggregated using the given reduce function func.\n",
    "    + calculate the function (value) on the partition first, and then merge using the unique key\n",
    "    + reduceByKey and groupByKey will require less data shuffle by grouping the values together by key vs. mapValues (i.e. more computationally expensive)\n",
    "    + To group values for the purpose of aggregation using reduceByKey(), foldByKey() or combineByKey() will provide worse performance since they combines the aggregation function before the shuffle.\n",
    "    \n",
    "    \n",
    "- **`combineByKey(createCombiner, mergeValue, mergeCombiners)`**:\n",
    "    + Similar to `aggregate()`.\n",
    "    + **`createCombiner`** - If it is new in a partition (not an RDD!), create the initial value for the accumulator on the key.\n",
    "    + **`mergeValue`** - If it is not new in the partition, apply the mergeValue function. \n",
    "    + **`mergeCombiners`** - Since each partition is processed independently, we can have multiple accumulators for the same key. When merging the results from each partition, apply the mergeCombiners to merge the accumulators for the same key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Operations don't shuffle data: `mapValues`, `flatMapValues`. \n",
    "- Operations shuffle data: `groupByKey`, `reduceByKey`, `combineByKey`, `sortByKey`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, u'#'),\n",
       " (6, u'Apache'),\n",
       " (5, u'Spark'),\n",
       " (0, u''),\n",
       " (5, u'Spark'),\n",
       " (2, u'is'),\n",
       " (1, u'a'),\n",
       " (4, u'fast'),\n",
       " (3, u'and'),\n",
       " (7, u'general')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate key-value pairs of (length of word, word)\n",
    "words = lines.flatMap(lambda l: l.split(\" \"))\n",
    "words_length = words.map(lambda x: (len(x),x))\n",
    "words_length.collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 5, 0, 5, 2, 1, 4, 3, 7]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_length.keys().collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'#',\n",
       " u'Apache',\n",
       " u'Spark',\n",
       " u'',\n",
       " u'Spark',\n",
       " u'is',\n",
       " u'a',\n",
       " u'fast',\n",
       " u'and',\n",
       " u'general']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_length.values().collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, u'one'),\n",
       " (6, u'stream'),\n",
       " (4, u'Hive'),\n",
       " (7, u'package'),\n",
       " (7, u'module,'),\n",
       " (5, u'them,'),\n",
       " (4, u'uses'),\n",
       " (3, u'set'),\n",
       " (6, u'thread'),\n",
       " (5, u'start')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_length.sortByKey(ascending=True).distinct().collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, <pyspark.resultiterable.ResultIterable at 0x10ba33d10>),\n",
       " (112, <pyspark.resultiterable.ResultIterable at 0x10ba3f1d0>),\n",
       " (2, <pyspark.resultiterable.ResultIterable at 0x10ba3f250>),\n",
       " (4, <pyspark.resultiterable.ResultIterable at 0x10ba3f290>),\n",
       " (6, <pyspark.resultiterable.ResultIterable at 0x10ba3f2d0>),\n",
       " (8, <pyspark.resultiterable.ResultIterable at 0x10ba3f310>),\n",
       " (96, <pyspark.resultiterable.ResultIterable at 0x10ba3f350>),\n",
       " (10, <pyspark.resultiterable.ResultIterable at 0x10ba3f390>),\n",
       " (12, <pyspark.resultiterable.ResultIterable at 0x10ba3f3d0>),\n",
       " (18, <pyspark.resultiterable.ResultIterable at 0x10ba3f410>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pair RDD with (length of a word, list of words) from “README.md”.\n",
    "# return iterable object\n",
    "words_length.groupByKey().collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10,\n",
       "  [u'high-level',\n",
       "   u'downloaded',\n",
       "   u'[\"Parallel',\n",
       "   u'[\"Building',\n",
       "   u'developing',\n",
       "   u'`examples`',\n",
       "   u'directory.',\n",
       "   u'[params]`.',\n",
       "   u'\"local[N]\"',\n",
       "   u'`examples`',\n",
       "   u'individual',\n",
       "   u'particular',\n",
       "   u'particular'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return words with length=10\n",
    "words_length.groupByKey().map(lambda x: (x[0], list(x[1]))).filter(lambda x: x[0]==10).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate key-value pairs of (word, occurence)\n",
    "words = lines.flatMap(lambda l: l.split(\" \"))\n",
    "words_occr = words.map(lambda x: (x,1)).groupByKey().map(lambda x: (x[0], list(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'', 68),\n",
       " (u'when', 1),\n",
       " (u'R,', 1),\n",
       " (u'including', 3),\n",
       " (u'computation', 1),\n",
       " (u'using:', 1),\n",
       " (u'guidance', 2),\n",
       " (u'Scala,', 1),\n",
       " (u'environment', 1),\n",
       " (u'only', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_occr = words_occr.map(lambda x: (x[0], sum(x[1])))\n",
    "words_occr.collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = sc.textFile(\"./data/README.md\").filter(lambda x : \"spark\" in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_word_pair = word.map(lambda x : (len(x),x))\n",
    "len_word_pair_group = len_word_pair.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(76, <pyspark.resultiterable.ResultIterable at 0x10f6a6850>),\n",
       "  (84, <pyspark.resultiterable.ResultIterable at 0x10f6a6bd0>),\n",
       "  (54, <pyspark.resultiterable.ResultIterable at 0x10f6a67d0>),\n",
       "  (120, <pyspark.resultiterable.ResultIterable at 0x10f6a65d0>),\n",
       "  (26, <pyspark.resultiterable.ResultIterable at 0x10f6a6790>),\n",
       "  (62, <pyspark.resultiterable.ResultIterable at 0x10f6a6650>)],\n",
       " [(97, <pyspark.resultiterable.ResultIterable at 0x10f784510>),\n",
       "  (21, <pyspark.resultiterable.ResultIterable at 0x10f784050>),\n",
       "  (17, <pyspark.resultiterable.ResultIterable at 0x10f784190>)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_word_pair_group.mapValues(lambda x : x).glom().collect()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(76,\n",
       "   u'guide, on the [project web page](http://spark.apache.org/documentation.html)'),\n",
       "  (76,\n",
       "   u'[\"Building Spark\"](http://spark.apache.org/docs/latest/building-spark.html).'),\n",
       "  (84,\n",
       "   u'Testing first requires [building Spark](#building-spark). Once Spark is built, tests'),\n",
       "  (54, u'    MASTER=spark://host:7077 ./bin/run-example SparkPi'),\n",
       "  (120,\n",
       "   u'[\"Specifying the Hadoop Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)'),\n",
       "  (26, u'<http://spark.apache.org/>'),\n",
       "  (62, u'examples to a cluster. This can be a mesos:// or spark:// URL,')],\n",
       " [(97,\n",
       "   u'Please refer to the [Configuration Guide](http://spark.apache.org/docs/latest/configuration.html)'),\n",
       "  (21, u'    ./bin/spark-shell'),\n",
       "  (17, u'    ./bin/pyspark')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_word_pair_group.flatMapValues(lambda x : x).glom().collect()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate key-value pairs of (word, occurence) using reduceByKey\n",
    "words = lines.flatMap(lambda l: l.split(\" \"))\n",
    "words_occr = words.map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'', 68),\n",
       " (u'when', 1),\n",
       " (u'R,', 1),\n",
       " (u'including', 3),\n",
       " (u'computation', 1),\n",
       " (u'using:', 1),\n",
       " (u'guidance', 2),\n",
       " (u'Scala,', 1),\n",
       " (u'environment', 1),\n",
       " (u'only', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_occr.collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, u'#'),\n",
       " (6, u'Apache'),\n",
       " (5, u'Spark'),\n",
       " (0, u''),\n",
       " (5, u'Spark'),\n",
       " (2, u'is'),\n",
       " (1, u'a'),\n",
       " (4, u'fast'),\n",
       " (3, u'and'),\n",
       " (7, u'general')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create pairs (length of words, (frequency, a list of words)) using combineByKey()\n",
    "# step: textFile -> flatMap(x.split()) -> map((len(x), x))\n",
    "words_length = words.map(lambda x: (len(x),x))\n",
    "words_length.collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  (68,\n",
       "   u',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,')),\n",
       " (1, (11, u'#,a,a,a,a,a,a,N,a,A,a')),\n",
       " (2,\n",
       "  (70,\n",
       "   u'is,It,in,R,,an,It,of,##,on,##,is,To,do,to,do,if,by,-T,in,is,at,an,##,to,is,to,##,if,##,in,To,of,Pi,to,to,be,or,to,on,to,or,to,an,if,is,in,of,if,no,##,is,be,on,to,or,##,to,to,in,of,to,at,on,of,##,to,in,an,on,to')),\n",
       " (3,\n",
       "  (94,\n",
       "   u'and,for,Big,and,and,for,set,SQL,for,SQL,and,for,for,and,for,You,can,the,the,web,and,and,its,not,you,You,can,one,the,see,the,For,see,and,The,way,the,Try,the,you,you,can,use,the,And,run,the,>>>,the,run,one,use,For,run,the,You,can,set,the,can,run,and,run,one,run,You,can,use,the,the,For,the,are,can,run,see,the,how,for,the,and,the,you,the,the,the,for,for,for,and,the,the,for,how')),\n",
       " (4,\n",
       "  (47,\n",
       "   u'fast,APIs,that,data,also,rich,find,This,file,only,run:,(You,need,this,more,than,with,More,from,IDE,,also,also,with,will,when,This,URL,,with,with,also,name,Many,help,Once,[run,Note,uses,core,talk,HDFS,have,must,same,that,your,Hive,Hive'))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs = words_length.combineByKey((lambda x: (1, x)), #createCombiner - if you see the word for the first time\n",
    "                                      (lambda x, y: (x[0]+1, x[1]+\",\"+y)), # mergeValue\n",
    "                                      (lambda x, y: (x[0]+y[0], x[1]+\",\"+y[1]))) # mergeCombiner\n",
    "\n",
    "word_pairs.sortBy(lambda x: x[0]).collect()[:5]                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
